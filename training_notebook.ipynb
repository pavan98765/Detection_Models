{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training yolov8 models on custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1694405950092,
     "user": {
      "displayName": "will b",
      "userId": "17404034164264469163"
     },
     "user_tz": -330
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "efb10e2a-4eca-4295-d02a-e37ad8f9c0e2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13652,
     "status": "ok",
     "timestamp": 1694405963738,
     "user": {
      "displayName": "will b",
      "userId": "17404034164264469163"
     },
     "user_tz": -330
    },
    "id": "tdSMcABDNKW-"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.134\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download the dataset from Roboflow [annotator tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 27056,
     "status": "ok",
     "timestamp": 1694405990786,
     "user": {
      "displayName": "will b",
      "userId": "17404034164264469163"
     },
     "user_tz": -330
    },
    "id": "BSd93ZJzZZKt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "%cd datasets\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"your-api-key-here\")\n",
    "project = rf.workspace(\"wce-fpcql\").project(\"wce_clean_train_2.0\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=50 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=val model=/content/datasets/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction / Inference with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=/path/to/your/weights/best.pt conf=0.25 source=/path/to/your/test/images save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU claculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def yolo_to_coords(yolo_format):\n",
    "    center_x, center_y, width, height = yolo_format\n",
    "    x1 = (center_x - width / 2)\n",
    "    y1 = (center_y - height / 2)\n",
    "    x2 = (center_x + width / 2)\n",
    "    y2 = (center_y + height / 2)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    x1_intersection = max(x1_1, x1_2)\n",
    "    y1_intersection = max(y1_1, y1_2)\n",
    "    x2_intersection = min(x2_1, x2_2)\n",
    "    y2_intersection = min(y2_1, y2_2)\n",
    "    \n",
    "    # Calculate the area of the intersection rectangle\n",
    "    intersection_area = max(0, x2_intersection - x1_intersection) * max(0, y2_intersection - y1_intersection)\n",
    "    \n",
    "    # Calculate the areas of the predicted and ground truth rectangles\n",
    "    area_box1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area_box2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    \n",
    "    # Calculate the union area\n",
    "    union_area = area_box1 + area_box2 - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def calculate_iou_for_folders(ground_truth_folder, predicted_labels_folder):\n",
    "    iou_list = []\n",
    "    \n",
    "    # Get the list of filenames in the ground truth folder\n",
    "    file_names = os.listdir(ground_truth_folder)\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        # Construct the full file paths for ground truth and predicted labels\n",
    "        ground_truth_file_path = os.path.join(ground_truth_folder, file_name)\n",
    "        predicted_file_path = os.path.join(predicted_labels_folder, file_name)\n",
    "        \n",
    "        # Read and process the files to calculate IoU\n",
    "        with open(ground_truth_file_path, 'r') as ground_truth_file, open(predicted_file_path, 'r') as predicted_file:\n",
    "            ground_truth_lines = ground_truth_file.readlines()\n",
    "            predicted_lines = predicted_file.readlines()\n",
    "        \n",
    "        # Parse YOLO format lines into lists of bounding boxes\n",
    "        ground_truth_bboxes = [list(map(float, line.strip().split()[1:])) for line in ground_truth_lines]\n",
    "        predicted_bboxes = [list(map(float, line.strip().split()[1:])) for line in predicted_lines]\n",
    "        \n",
    "        # Convert YOLO format to (x1, y1, x2, y2) format for each bounding box\n",
    "        ground_truth_bboxes = [yolo_to_coords(bbox) for bbox in ground_truth_bboxes]\n",
    "        predicted_bboxes = [yolo_to_coords(bbox) for bbox in predicted_bboxes]\n",
    "        \n",
    "        # Calculate IoU for each pair of bounding boxes\n",
    "        ious = []\n",
    "        for predicted_bbox in predicted_bboxes:\n",
    "            for ground_truth_bbox in ground_truth_bboxes:\n",
    "                iou = calculate_iou(predicted_bbox, ground_truth_bbox)\n",
    "                ious.append(iou)\n",
    "        \n",
    "        # Choose the maximum IoU as the final IoU for this case\n",
    "        max_iou = max(ious)\n",
    "        \n",
    "        # Append the max IoU to the list\n",
    "        iou_list.append(max_iou)\n",
    "    \n",
    "    # Calculate the mean IoU\n",
    "    mean_iou = sum(iou_list) / len(iou_list)\n",
    "    \n",
    "    return iou_list, mean_iou\n",
    "\n",
    "# Example usage:\n",
    "ground_truth_folder = \"/path/to/ground_truth_labels\"\n",
    "predicted_labels_folder = \"/path/to/predicted_labels\"\n",
    "ious, mean_iou = calculate_iou_for_folders(ground_truth_folder, predicted_labels_folder)\n",
    "# print(\"IoUs for all files:\", ious)\n",
    "print(\"Mean IoU:\", mean_iou)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability plots generation ( occlusion plots )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory containing the images and the output directory for occlusion plots\n",
    "image_directory = \"path_to_image_directory\"  # Update with your image directory path\n",
    "output_directory = \"path_to_output_directory\"  # Update with your output directory path\n",
    "\n",
    "# List all image files in the image directory\n",
    "image_files = [f for f in os.listdir(image_directory) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Assuming you have a YOLO model (model_path should be defined and initialized)\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_directory, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Generate occlusion plots\n",
    "    occluded_images = generate_occluded_images(image, occlusion_size=(100, 100), step_size=20)\n",
    "\n",
    "    # Divide the image into 9 regions\n",
    "    image_height, image_width, _ = image.shape\n",
    "    region_height = image_height // 3\n",
    "    region_width = image_width // 3\n",
    "    regions = [(j * region_width, i * region_height, (j + 1) * region_width, (i + 1) * region_height) for i in range(3) for j in range(3)]\n",
    "\n",
    "    # Create subplots to display the occlusion images\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "    for i, region in enumerate(regions):\n",
    "        region_image = copy(image)\n",
    "        x1, y1, x2, y2 = region\n",
    "        region_image[y1:y2, x1:x2] = 0\n",
    "\n",
    "        # Run the occluded image through the YOLO model and get results\n",
    "        results_occluded = model(region_image)\n",
    "\n",
    "        # Extract bounding boxes from YOLO results on the occluded image\n",
    "        xyxys_occluded = []\n",
    "        confidences = []\n",
    "        for result in results_occluded:\n",
    "            boxes = result.boxes\n",
    "            xyxys_occluded.extend(boxes.xyxy.tolist())\n",
    "            confidences.extend(boxes.conf.tolist())\n",
    "\n",
    "        occlusion_plot_image_with_boxes = copy(region_image)\n",
    "        for bbox, confidence in zip(xyxys_occluded, confidences):\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            cv2.rectangle(occlusion_plot_image_with_boxes, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "            confidence_text = f\"{confidence:.2f}\"\n",
    "            cv2.putText(occlusion_plot_image_with_boxes, confidence_text, (x2-40, y1 + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        row, col = i // 3, i % 3\n",
    "        axes[row, col].imshow(cv2.cvtColor(occlusion_plot_image_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "        axes[row, col].set_title(f\"Occlusion {i + 1}\")\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    # Save the final big subplot with the original image name (without extension)\n",
    "    filename, _ = os.path.splitext(image_file)\n",
    "    output_path = os.path.join(output_directory, filename)\n",
    "    output_file = f\"{output_path}.png\"\n",
    "    fig.savefig(output_file)\n",
    "\n",
    "    # Close the plot\n",
    "    plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "provenance": [
    {
     "file_id": "https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb",
     "timestamp": 1693909905905
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
